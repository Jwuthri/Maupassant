{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import glob, pickle, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maupassant.feature_extraction.embedding import BertEmbedding\n",
    "from maupassant.training_utils import TrainerHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_module = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\", input_shape=[], dtype=tf.string, trainable=False, name='multilingual_embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(model_dir):\n",
    "    encoders_files = glob.glob(model_dir + \"/*encoder.pkl\")\n",
    "    encoders = {}\n",
    "    for file in encoders_files:\n",
    "        encoder = pickle.load(open(file, \"rb\"))\n",
    "        encoder_name = os.path.split(file)[1].split('.')[0]\n",
    "        encoders[encoder_name] = dict(enumerate(encoder.classes_))\n",
    "\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"/home/jwuthri/Documents/GitHub/Maupassant/maupassant/models/one_to_one_2020_03_24_21_13_29\", \n",
    "    \"/home/jwuthri/Documents/GitHub/Maupassant/maupassant/models/one_to_one_2020_03_25_10_52_14\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jwuthri/Documents/GitHub/Maupassant/maupassant/models/one_to_one_2020_03_24_21_13_29\"\n",
    "latest = tf.train.latest_checkpoint(path)\n",
    "encoder = load_encoder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc652550a90>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = tf.keras.Input((), dtype=tf.string, name=\"input_layer\")\n",
    "embedding_layer = bert_module(input_layer)\n",
    "reshape_layer = tf.keras.layers.Reshape(target_shape=(1, 512))(embedding_layer)\n",
    "conv_layer = tf.keras.layers.Conv1D(512, 3, padding='same', activation='relu', strides=1)(reshape_layer)\n",
    "gpooling_layer = tf.keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "flatten_layer = tf.keras.layers.Flatten()(gpooling_layer)\n",
    "dense_layer = tf.keras.layers.Dense(250, activation=\"relu\")(flatten_layer)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.25)(dense_layer)\n",
    "layer1 = tf.keras.layers.Dense(8, activation=\"sigmoid\", name=\"sentiment\")(dropout_layer)\n",
    "sentiment = tf.keras.models.Model(inputs=input_layer, outputs=layer1)\n",
    "sentiment.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_sentiment(x):\n",
    "    proba = sentiment.predict(np.asarray([x]))[0]\n",
    "    for k, v in encoder.items():\n",
    "        preds = [(v[label], th) for label, th in enumerate(proba) if th >= 0.5]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('toxic', 0.95566)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sentiment(\"I will not buy from you anymore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jwuthri/Documents/GitHub/Maupassant/maupassant/models/one_to_one_2020_03_25_10_52_14\"\n",
    "latest = tf.train.latest_checkpoint(path)\n",
    "encoder = load_encoder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc65214a590>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = tf.keras.Input((), dtype=tf.string, name=\"input_layer\")\n",
    "embedding_layer = bert_module(input_layer)\n",
    "reshape_layer = tf.keras.layers.Reshape(target_shape=(1, 512))(embedding_layer)\n",
    "conv_layer = tf.keras.layers.Conv1D(512, 3, padding='same', activation='relu', strides=1)(reshape_layer)\n",
    "gpooling_layer = tf.keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "flatten_layer = tf.keras.layers.Flatten()(gpooling_layer)\n",
    "dense_layer = tf.keras.layers.Dense(250, activation=\"relu\")(flatten_layer)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.25)(dense_layer)\n",
    "layer = tf.keras.layers.Dense(25, activation=\"sigmoid\", name=\"intent\")(dropout_layer)\n",
    "intent = tf.keras.models.Model(inputs=input_layer, outputs=layer)\n",
    "intent.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_intent(x):\n",
    "    proba = intent.predict(np.asarray([x]))[0]\n",
    "    for k, v in encoder.items():\n",
    "        preds = [(v[label], th) for label, th in enumerate(proba) if th >= 0.5]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shipping/status', 1.0)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_intent(\"Where is my order?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.Input((), dtype=tf.string, name=\"input_layer\")\n",
    "embedding_layer = bert_module(input_layer)\n",
    "reshape_layer = tf.keras.layers.Reshape(target_shape=(1, 512))(embedding_layer)\n",
    "outs = []\n",
    "for model in [sentiment, intent]:\n",
    "    conv_layer = model.layers[3](reshape_layer)\n",
    "    gpooling_layer = model.layers[4](conv_layer)\n",
    "    flatten_layer = model.layers[5](gpooling_layer)\n",
    "    dense_layer = model.layers[6](flatten_layer)\n",
    "    dropout_layer = model.layers[7](dense_layer)\n",
    "    layer = model.layers[8](dropout_layer)\n",
    "    outs.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=input_layer, outputs=outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.71 ms ± 76.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model.predict(np.asarray(['Hello retard, where is my order?']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 9.9997437e-01, 1.6412139e-04,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3952255e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.asarray(['Hello retard, where is my order?']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.asarray(['Hello retard, where is my order?']))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jwuthri/Documents/GitHub/Maupassant/maupassant/models/one_to_one_2020_03_24_21_13_29\"\n",
    "sent_encoder = load_encoder(path)\n",
    "\n",
    "path = \"/home/jwuthri/Documents/GitHub/Maupassant/maupassant/models/one_to_one_2020_03_25_10_52_14\"\n",
    "intent_encoder = load_encoder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('intent_sentiment_model/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint('intent_sentiment_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.Input((), dtype=tf.string, name=\"input_layer\")\n",
    "embedding_layer = bert_module(input_layer)\n",
    "reshape_layer = tf.keras.layers.Reshape(target_shape=(1, 512))(embedding_layer)\n",
    "outs = []\n",
    "for model in ['sentiment', 'intent']:\n",
    "    n_classes = 25 if model == 'intent' else 8\n",
    "    conv_layer = tf.keras.layers.Conv1D(512, 3, padding='same', activation='relu', strides=1)(reshape_layer)\n",
    "    gpooling_layer = tf.keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(gpooling_layer)\n",
    "    dense_layer = tf.keras.layers.Dense(250, activation=\"relu\")(flatten_layer)\n",
    "    dropout_layer = tf.keras.layers.Dropout(0.25)(dense_layer)\n",
    "    layer = tf.keras.layers.Dense(n_classes, activation=\"sigmoid\", name=model)(dropout_layer)\n",
    "    outs.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc7a14f6150>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.Model(inputs=input_layer, outputs=outs)\n",
    "loaded_model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.0000000e+00, 0.0000000e+00, 9.9997437e-01, 1.6412139e-04,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3952255e-02]],\n",
       "       dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(np.asarray(['Hello retard, where is my order?']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multilingual_embed (KerasLayer) (None, 512)          68927232    input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 512)       0           multilingual_embed[22][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1, 512)       786944      reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1, 512)       786944      reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 512)          0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 512)          0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 512)          0           global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 512)          0           global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 250)          128250      flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 250)          128250      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 250)          0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 250)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sentiment (Dense)               (None, 8)            2008        dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "intent (Dense)                  (None, 25)           6275        dropout_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,765,903\n",
      "Trainable params: 1,838,671\n",
      "Non-trainable params: 68,927,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intent'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.layers[-1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentiment'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.layers[-2].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = load_encoder('intent_sentiment_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "pba = loaded_model.predict(np.asarray(['I am angry, I want a refund']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(zip(encoders, pba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('negativ', 1.0), ('toxic', 0.9999999)]\n",
      "[('refund/request', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "for pred in preds:\n",
    "    v = encoders[pred[0]]\n",
    "    res = [(v[label], th) for label, th in enumerate(pred[1][0]) if th >= 0.5]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_format(x):\n",
    "    if isinstance(x, str):\n",
    "        x = np.asarray([x])\n",
    "    if isinstance(x, list):\n",
    "        x = np.asarray(x)\n",
    "\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
